From a925b9b749be4413240fb260b115401cddb8746e Mon Sep 17 00:00:00 2001
From: Ryan Blue <rblue@cloudera.com>
Date: Tue, 23 Sep 2014 12:14:17 -0700
Subject: [PATCH 30/93] PARQUET-82: Check page size is valid when writing.

Author: Ryan Blue <rblue@cloudera.com>

Closes #48 from rdblue/PARQUET-82-check-page-size and squashes the following commits:

9f31402 [Ryan Blue] PARQUET-82: Check page size is valid when writing.
---
 .../parquet/hadoop/ColumnChunkPageWriteStore.java  |   20 ++++++++++++++++++++
 1 files changed, 20 insertions(+), 0 deletions(-)

diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java b/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
index 279eb56..6d7f685 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
@@ -77,8 +77,18 @@ class ColumnChunkPageWriteStore implements PageWriteStore {
                           Encoding dlEncoding,
                           Encoding valuesEncoding) throws IOException {
       long uncompressedSize = bytes.size();
+      if (uncompressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write page larger than Integer.MAX_VALUE bytes: " +
+                uncompressedSize);
+      }
       BytesInput compressedBytes = compressor.compress(bytes);
       long compressedSize = compressedBytes.size();
+      if (compressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write compressed page larger than Integer.MAX_VALUE bytes: "
+                + compressedSize);
+      }
       BooleanStatistics statistics = new BooleanStatistics(); // dummy stats object
       parquetMetadataConverter.writeDataPageHeader(
           (int)uncompressedSize,
@@ -107,8 +117,18 @@ class ColumnChunkPageWriteStore implements PageWriteStore {
                           Encoding dlEncoding,
                           Encoding valuesEncoding) throws IOException {
       long uncompressedSize = bytes.size();
+      if (uncompressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write page larger than Integer.MAX_VALUE bytes: " +
+            uncompressedSize);
+      }
       BytesInput compressedBytes = compressor.compress(bytes);
       long compressedSize = compressedBytes.size();
+      if (compressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write compressed page larger than Integer.MAX_VALUE bytes: "
+            + compressedSize);
+      }
       parquetMetadataConverter.writeDataPageHeader(
           (int)uncompressedSize,
           (int)compressedSize,
-- 
1.7.0.4

